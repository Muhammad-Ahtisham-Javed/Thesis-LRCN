{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"X3AdbpZFCRR0"},"outputs":[],"source":["import os\n","import cv2\n","import math\n","import random\n","import numpy as np\n","import datetime as dt\n","import tensorflow as tf\n","from collections import deque\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.utils import plot_model\n","from sklearn.model_selection import train_test_split\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","DATASET_DIR = \"/content/drive/Othercomputers/My Laptop/Thesis/UCF50\"\n","IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n","SEQUENCE_LENGTH = 10\n","CLASSES_LIST = os.listdir(DATASET_DIR)\n","CLASSES_LIST = CLASSES_LIST[:10]\n","seed_constant = 27\n","np.random.seed(seed_constant)\n","random.seed(seed_constant)\n","tf.random.set_seed(seed_constant)\n","\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1661597039642,"user":{"displayName":"MSCSF20M514-MUHAMMAD AHTISHAM","userId":"09616800509644013848"},"user_tz":-300},"id":"zBu224OG-szz"},"outputs":[],"source":["def frames_extraction(video_path):\n","  frames_list = []\n","  video_reader = cv2.VideoCapture(video_path)\n","  video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n","  skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n","  for frame_counter in range(SEQUENCE_LENGTH):\n","    video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n","    success, frame = video_reader.read() \n","    if not success:\n","      break\n","    resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n","    normalized_frame = resized_frame / 255\n","    frames_list.append(normalized_frame)\n","  video_reader.release()\n","  return frames_list"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1661597039642,"user":{"displayName":"MSCSF20M514-MUHAMMAD AHTISHAM","userId":"09616800509644013848"},"user_tz":-300},"id":"j6MLp9PpDJ4-"},"outputs":[],"source":["def create_dataset():\n","  features = []\n","  labels = []\n","  video_files_paths = []\n","  \n","  for class_index, class_name in enumerate(CLASSES_LIST):\n","    print(f'Extracting Data of Class: {class_name}')\n","    files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n","    for file_name in files_list:\n","      video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n","      frames = frames_extraction(video_file_path)\n","      if len(frames) == SEQUENCE_LENGTH:\n","        features.append(frames)\n","        labels.append(class_index)\n","        video_files_paths.append(video_file_path)\n","\n","  features = np.asarray(features)\n","  labels = np.array(labels)  \n","  return features, labels, video_files_paths"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1661597039643,"user":{"displayName":"MSCSF20M514-MUHAMMAD AHTISHAM","userId":"09616800509644013848"},"user_tz":-300},"id":"h8cDSpfXJXwx"},"outputs":[],"source":["def create_convlstm_model():\n","  model = Sequential()\n","  \n","  model.add(ConvLSTM2D(filters=4, kernel_size=(3, 3), activation='tanh', data_format=\"channels_last\",\n","                        recurrent_dropout=0.2, return_sequences=True, input_shape = (SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n","  \n","  model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n","  model.add(TimeDistributed(Dropout(0.2)))\n","  \n","  model.add(ConvLSTM2D(filters=8, kernel_size=(3, 3), activation='tanh', data_format=\"channels_last\",\n","                        recurrent_dropout=0.2, return_sequences=True))\n","  \n","  model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n","  model.add(TimeDistributed(Dropout(0.2)))\n","  \n","  model.add(ConvLSTM2D(filters=14, kernel_size=(3, 3), activation='tanh', data_format=\"channels_last\",\n","                        recurrent_dropout=0.2, return_sequences=True))\n","  \n","  model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n","  model.add(TimeDistributed(Dropout(0.2)))\n","  \n","  model.add(ConvLSTM2D(filters=16, kernel_size=(3, 3), activation='tanh', data_format=\"channels_last\",\n","                        recurrent_dropout=0.2, return_sequences=True))\n","  \n","  model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n","  model.add(TimeDistributed(Dropout(0.2)))\n","  \n","  model.add(Flatten()) \n","\n","  model.add(Dense(len(CLASSES_LIST), activation = \"softmax\"))\n","\n","  print(model.summary())\n","\n","  plot_model(model, to_file = 'convlstm_model.png', show_shapes=True, show_layer_names=True)\n","\n","  return model"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1661597039644,"user":{"displayName":"MSCSF20M514-MUHAMMAD AHTISHAM","userId":"09616800509644013848"},"user_tz":-300},"id":"qrQnmVF7aZjQ"},"outputs":[],"source":["def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name, x_label, y_label, save_name):\n","  metric_value_1 = model_training_history.history[metric_name_1]\n","  metric_value_2 = model_training_history.history[metric_name_2]\n","\n","  epochs = range(len(metric_value_1))\n","\n","  plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n","  plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n","  plt.title(str(plot_name))\n","\n","  plt.legend()\n","  plt.xlabel(x_label)\n","  plt.ylabel(y_label)\n","  plt.savefig(save_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2D1CS2Z6Jkp5"},"outputs":[],"source":["features, labels, video_files_paths = create_dataset()\n","one_hot_encoded_labels = to_categorical(labels)\n","\n","features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels,\n","                                                                            test_size=0.25, shuffle=True, random_state=seed_constant)\n","\n","early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, mode='min', restore_best_weights=True)\n","convlstm_model = create_convlstm_model()\n","convlstm_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=tf.keras.metrics.CategoricalAccuracy())\n","convlstm_model_training_history = convlstm_model.fit(x=features_train, y=labels_train, epochs=50, batch_size=4, shuffle=True,\n","                                                     validation_split=0.2, callbacks=[early_stopping_callback])\n","\n","plot_metric(convlstm_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss', 'Epochs', 'Loss', 'convlstm_loss_plot')\n","\n","print('-------------------------Evaluating model now-------------------------')\n","model_evaluation_history = convlstm_model.evaluate(features_test, labels_test)\n","model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n","\n","# Define the string date format.\n","# Get the current Date and Time in a DateTime Object.\n","# Convert the DateTime object to string according to the style mentioned in date_time_format string.\n","date_time_format = '%Y_%m_%d__%H_%M_%S'\n","current_date_time_dt = dt.datetime.now()\n","current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n","\n","# Define a useful name for our model to make it easy for us while navigating through multiple saved models.\n","model_file_name = f'convlstm_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n","\n","# Save your Model.\n","convlstm_model.save(model_file_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cTSpJP-bb7WV"},"outputs":[],"source":["plot_metric(convlstm_model_training_history, 'categorical_accuracy', 'val_categorical_accuracy', 'Total Accuracy vs Total Validation Accuracy',\n","            'Epochs', 'Accuracy', 'convlstm_accuracy_plot')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"ConvLSTM.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}