{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LRCN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPDgHd0H3IIU4KngUJ0MZA7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"651xZxENieOC"},"outputs":[],"source":["import os\n","import cv2\n","import math\n","import random\n","import numpy as np\n","import datetime as dt\n","import tensorflow as tf\n","from collections import deque\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.utils import plot_model\n","from sklearn.model_selection import train_test_split\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","DATASET_DIR = \"/content/drive/Othercomputers/My Laptop/Thesis/UCF50\"\n","IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n","SEQUENCE_LENGTH = 10\n","CLASSES_LIST = os.listdir(DATASET_DIR)\n","CLASSES_LIST = CLASSES_LIST[:10]\n","seed_constant = 27\n","np.random.seed(seed_constant)\n","random.seed(seed_constant)\n","tf.random.set_seed(seed_constant)\n","\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"]},{"cell_type":"code","source":["def frames_extraction(video_path):\n","  frames_list = []\n","  video_reader = cv2.VideoCapture(video_path)\n","  video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n","  skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n","  for frame_counter in range(SEQUENCE_LENGTH):\n","    video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n","    success, frame = video_reader.read() \n","    if not success:\n","      break\n","    resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n","    normalized_frame = resized_frame / 255\n","    frames_list.append(normalized_frame)\n","  video_reader.release()\n","  return frames_list"],"metadata":{"id":"TCoAKtsI2XKe","executionInfo":{"status":"ok","timestamp":1661598432204,"user_tz":-300,"elapsed":16,"user":{"displayName":"MSCSF20M514-MUHAMMAD AHTISHAM","userId":"09616800509644013848"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def create_dataset():\n","  features = []\n","  labels = []\n","  video_files_paths = []\n","  \n","  for class_index, class_name in enumerate(CLASSES_LIST):\n","    print(f'Extracting Data of Class: {class_name}')\n","    files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n","    for file_name in files_list:\n","      video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n","      frames = frames_extraction(video_file_path)\n","      if len(frames) == SEQUENCE_LENGTH:\n","        features.append(frames)\n","        labels.append(class_index)\n","        video_files_paths.append(video_file_path)\n","\n","  features = np.asarray(features)\n","  labels = np.array(labels)  \n","  return features, labels, video_files_paths"],"metadata":{"id":"ojbu9O3l2awZ","executionInfo":{"status":"ok","timestamp":1661598433288,"user_tz":-300,"elapsed":35,"user":{"displayName":"MSCSF20M514-MUHAMMAD AHTISHAM","userId":"09616800509644013848"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def create_LRCN_model():\n","  model = Sequential()\n","  \n","  model.add(TimeDistributed(Conv2D(16, (3, 3), padding='same',activation = 'relu'), input_shape=(SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n","  \n","  model.add(TimeDistributed(MaxPooling2D((4, 4))))\n","  model.add(TimeDistributed(Dropout(0.25)))\n","  \n","  model.add(TimeDistributed(Conv2D(32, (3, 3), padding='same',activation = 'relu')))\n","  model.add(TimeDistributed(MaxPooling2D((4, 4))))\n","  model.add(TimeDistributed(Dropout(0.25)))\n","  \n","  model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same',activation = 'relu')))\n","  model.add(TimeDistributed(MaxPooling2D((2, 2))))\n","  model.add(TimeDistributed(Dropout(0.25)))\n","  \n","  model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same',activation = 'relu')))\n","  model.add(TimeDistributed(MaxPooling2D((2, 2))))\n","  # model.add(TimeDistributed(Dropout(0.25)))\n","                                    \n","  model.add(TimeDistributed(Flatten()))\n","                                    \n","  model.add(LSTM(32))\n","                                    \n","  model.add(Dense(len(CLASSES_LIST), activation = 'softmax'))\n","\n","  model.summary()\n","\n","  plot_model(model, to_file = 'LRCN_model.png', show_shapes=True, show_layer_names=True)\n","\n","  return model"],"metadata":{"id":"_IeqWEv_2ecU","executionInfo":{"status":"ok","timestamp":1661598433289,"user_tz":-300,"elapsed":28,"user":{"displayName":"MSCSF20M514-MUHAMMAD AHTISHAM","userId":"09616800509644013848"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name, x_label, y_label, save_name):\n","  metric_value_1 = model_training_history.history[metric_name_1]\n","  metric_value_2 = model_training_history.history[metric_name_2]\n","\n","  epochs = range(len(metric_value_1))\n","\n","  plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n","  plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n","  plt.title(str(plot_name))\n","\n","  plt.legend()\n","  plt.xlabel(x_label)\n","  plt.ylabel(y_label)\n","  plt.savefig(save_name)"],"metadata":{"id":"SuBzs6Dw4CKu","executionInfo":{"status":"ok","timestamp":1661598433291,"user_tz":-300,"elapsed":27,"user":{"displayName":"MSCSF20M514-MUHAMMAD AHTISHAM","userId":"09616800509644013848"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["features, labels, video_files_paths = create_dataset()\n","one_hot_encoded_labels = to_categorical(labels)\n","\n","features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels,\n","                                                                            test_size=0.25, shuffle=True, random_state=seed_constant)\n","\n","early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min', restore_best_weights = True)\n","LRCN_model = create_LRCN_model()\n","LRCN_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=tf.keras.metrics.CategoricalAccuracy())\n","LRCN_model_training_history = LRCN_model.fit(x=features_train, y=labels_train, epochs=50, batch_size=4,\n","                                             shuffle=True, validation_split=0.2, callbacks=[early_stopping_callback])\n","\n","plot_metric(LRCN_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss', 'Epochs', 'Loss', 'lrcn_loss_plot')\n","\n","print('-------------------------Evaluating model now-------------------------')\n","model_evaluation_history = LRCN_model.evaluate(features_test, labels_test)\n","model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n","\n","# Define the string date format.\n","# Get the current Date and Time in a DateTime Object.\n","# Convert the DateTime object to string according to the style mentioned in date_time_format string.\n","date_time_format = '%Y_%m_%d__%H_%M_%S'\n","current_date_time_dt = dt.datetime.now()\n","current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n","    \n","# Define a useful name for our model to make it easy for us while navigating through multiple saved models.\n","model_file_name = f'LRCN_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n","\n","# Save the Model.\n","LRCN_model.save(model_file_name)"],"metadata":{"id":"j7HbqHBD22Xz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_metric(LRCN_model_training_history, 'categorical_accuracy', 'val_categorical_accuracy', 'Total Accuracy vs Total Validation Accuracy',\n","            'Epochs', 'Accuracy', 'lrcn_accuracy_plot')"],"metadata":{"id":"AQ2vrPP23rYo"},"execution_count":null,"outputs":[]}]}